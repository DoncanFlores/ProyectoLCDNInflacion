# -*- coding: utf-8 -*-
"""RegresionMulttiple.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yeFhjWzOz_JOFIRXyh9jTWwGvg61FEVf
"""

#Importando las librerias necesarias 
from google.colab import drive
from scipy.stats import norm
from sklearn.preprocessing import StandardScaler
from mpl_toolkits.mplot3d import Axes3D
from scipy import stats

import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

#Accediendo al archhivo csv del INPC en el periodo (Completar)
drive.mount('/content/drive')

#Asignando el arhivo a una variable
df=('/content/drive/MyDrive/MLenColab/Proyecto ErenInteligencia/INPC-8.csv')

#Creando el DataFrame con la libreria pandas
dfinpc = pd.read_csv(df)
dfinpc

#Eliminando las filas no deseadas
dfinpc = dfinpc.drop(range(0,16))
dfinpc

#Renombrando las columnas 
#Renombrando las columnas
dfinpc = dfinpc.rename(columns={'Instituto Nacional de Estadística y Geografía' : 'Fecha',
                                'Unnamed: 1' : 'INPC_Total',
                                'Unnamed: 2' : 'AlimenBebidNoAlcoholic',
                                'Unnamed: 3' : 'Alcohol&Tabaco',
                                'Unnamed: 4' : 'Vestido&Calzado',
                                'Unnamed: 5' : 'ServicPublideSuministro',
                                'Unnamed: 6' : 'Mobiliario',
                                'Unnamed: 7' : 'Salud',
                                'Unnamed: 8' : 'Transporte',
                                'Unnamed: 9' : 'Comunicaciones',
                                'Unnamed: 10' : 'Recreacion&Cultura',
                                'Unnamed: 11' : 'Educacion',
                                'Unnamed: 12' : 'Restaurant&Hotel',
                                'Unnamed: 13' : 'Diversos'})
dfinpc

#Quitando la columna de Fecha y sustituyendola con otra codificada que permita entender los datos 
#Y adaptarlos al modelo
dfinpc = dfinpc.drop('Fecha', axis = 1)
dfinpc.insert(0, 'Fechas', [22.01,22.02,22.03,22.04,22.05,22.06,22.07,22.08,22.09,22.10,22.11,22.12,23.01,23.02,23.03,23.04])
dfinpc

#Restableciendo los indices del DataFrame
dfinpc.reset_index(drop=True, inplace=True)
dfinpc

#Convirtiendo los datos del dataframe en datos numericos
dfinpc= dfinpc.applymap(lambda x: pd.to_numeric(x, errors='coerce'))
dfinpc

#Redondeando los datos de mi DataFrame a 2 decimales
dfinpc = dfinpc.round(2)
dfinpc

#Analizando nuestro DataFrame del INPC
dfinpc.describe()

# Commented out IPython magic to ensure Python compatibility.
#hacer que las gráficas se muestren directamente en la notebook
# %matplotlib inline 
from mpl_toolkits.mplot3d import Axes3D # Se utiliza para evitar la superposición de barras 
# de error cuando dos series comparten valores

from matplotlib import cm # Medida de longitud del sistema métrico 
plt.rcParams['figure.figsize'] = (16, 9)
plt.style.use('ggplot') # cambiará el estilo global y se aplicará a todos los gráficos de la sesión
from sklearn import linear_model #  proporciona acceso a versiones eficaces de muchos algoritmos comunes.

# contiene muchas herramientas eficientes para aprendizaje automático y modelado estadístico, 
# incluyendo clasificación, regresión, agrupación, y reducción de dimensionalidad
from sklearn.metrics import mean_squared_error, r2_score 
# muestra qué tan bien los términos (puntos de datos) se ajustan a una curva o línea

dfinpc.head()

# Visualizamos rápidamente las caraterísticas de entrada
dfinpc.drop(['Fechas'],1).hist()
plt.show()

#vamos a Visualizar los datos de entrada
colores=['orange','blue']
tamanios=[30,60]

f1 = dfinpc['Fechas'].values  # INPC Total
f2 = dfinpc['INPC_Total'].values # Fechas

# Vamos a pintar en 2 colores los puntos por debajo de la media de las fechas
asignar=[]
# iterrows(), recorrer cada fila del DataFrame y siempre devuelve un iterador que almacena datos de cada fila
for index, row in dfinpc.iterrows(): 
    if(row['Fechas']>22.30):
        asignar.append(colores[0])
    else:
        asignar.append(colores[1])
    
plt.scatter(f1, f2, c=asignar, s=tamanios[0])
plt.show()

# Vamos a RECORTAR los datos en la zona donde se concentran más los puntos
# esto es en el eje X: entre 0 y 22.2
# y en el eje Y: entre 0 y 8
filtered_data = dfinpc[(dfinpc['Fechas'] <= 22.2) & (dfinpc['INPC_Total'] <= 8)]

f1 = filtered_data['Fechas'].values
f2 = filtered_data['INPC_Total'].values

# Vamos a pintar en colores los puntos por debajo y por encima de la media de las fehcas
asignar=[]
for index, row in filtered_data.iterrows():
    if(row['Fechas']>22.30):
        asignar.append(colores[0])
    else:
        asignar.append(colores[1])
    
plt.scatter(f1, f2, c=asignar, s=tamanios[0])
plt.show()

# Veamos como cambian los valores una vez filtrados
filtered_data.describe()

# Asignamos nuestra variable de entrada X para entrenamiento y las etiquetas Y.
dataX =filtered_data[["Fechas"]]
X_train = np.array(dataX)
y_train = filtered_data['INPC_Total'].values

# Creamos el objeto de Regresión Linear
regr = linear_model.LinearRegression()

# Entrenamos nuestro modelo
regr.fit(X_train, y_train)

# Hacemos las predicciones que en definitiva una línea (en este caso, al ser 2D)
y_pred = regr.predict(X_train)

# Veamos los coeficienetes obtenidos, En nuestro caso, serán la Tangente
print('Coeficientes: \n', regr.coef_)
# Este es el valor donde corta el eje Y (en X=0)
print('Independiente term: \n', regr.intercept_)
# Error Cuadrado Medio
print("Error medio cuadrado: %.2f" % mean_squared_error(y_train, y_pred))
# Puntaje de Varianza. El mejor puntaje es un 1.0
print('puntuación de varianza: %.2f' % r2_score(y_train, y_pred))

#Visaulizando la recta
plt.scatter(X_train[:,0], y_train,  c=asignar, s=tamanios[0])
plt.plot(X_train[:,0], y_pred, color='red', linewidth=3)

plt.xlabel('Fechas')
plt.ylabel('INPC_Total')
plt.title('Regresión Lineal')

plt.show()

#Vamos a comprobar:
# Quiero predecir el INPC Total que voy a obtener en el año 22.06,
# según nuestro modelo, hacemos:
y_Pred = regr.predict([[22.06]])
print(int(y_Pred))

#Vamos a intentar mejorar el Modelo, con una dimensión más: 
# Para poder graficar en 3D, haremos una variable nueva que será el INPC de Alimentos & Bebidas no Alcoholicas
# suma = (filtered_data["# of Links"] + filtered_data['# of comments'].fillna(0) + filtered_data['# Images video'])

dataX2 =  pd.DataFrame()
dataX2["INPC_Total"] = filtered_data["INPC_Total"]
dataX2["suma"] = filtered_data['AlimenBebidNoAlcoholic'].values
XY_train = np.array(dataX2)
z_train = filtered_data['Fechas'].values

#Esta vez, nuestras dimensiones de entrenamiento serán X e Y y las etiquetas de predicción serán z
# Creamos un nuevo objeto de Regresión Lineal
regr2 = linear_model.LinearRegression()

# Entrenamos el modelo, esta vez, con 2 dimensiones
# obtendremos 2 coeficientes, para graficar un plano
regr2.fit(XY_train, z_train)

# Hacemos la predicción con la que tendremos puntos sobre el plano hallado
z_pred = regr2.predict(XY_train)

# Los coeficientes
print('Coeficientes: \n', regr2.coef_)
# Error cuadrático medio
print("Error medio cuadrado: %.2f" % mean_squared_error(z_train, z_pred))
# Evaluamos el puntaje de varianza (siendo 1.0 el mejor posible)
print('puntuación de varianza: %.2f' % r2_score(z_train, z_pred))

# Datos de INPC_Total y Bebidas Y Alimentos No alcholicas
XY_train = np.array([[0.59, 0.79],
                    [ 1.43, 1.62],
                    [ 2.43,  2.86],
                    [ 2.98,  4.12],
                    [ 3.17,  5.25],
                    [ 4.04,  6.83],
                    [ 4.81,  8.23],
                    [ 5.54,  9.64],
                    [ 6.19, 11.11],
                    [ 6.79, 11.6 ],
                    [ 7.41, 11.87],
                    [ 7.82, 12.7 ]])

#Datos de las fechas
z_train = np.array([22.01, 22.02, 22.03, 22.04, 22.05, 22.06, 22.07, 22.08, 22.09, 22.1,  22.11, 22.12])

#Datos de Bebidas y Alimentos No Alcoholicas
variable_adicional = np.array([0.79,1.62,2.86,4.12,5.25,6.83,8.23,9.64,11.11,11.60,11.87,12.70])

# Crear una figura
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

# Crear una malla
xx, yy = np.meshgrid(np.linspace(0, 10, num=10), np.linspace(0, 10, num=10))
nuevoX = (2 * xx)
nuevoY = (3 * yy)
z = (nuevoX + nuevoY + 5)

# Graficar el plano
ax.plot_surface(xx, yy, z, alpha=0.2, cmap='hot')

# Graficar los puntos en 3D
ax.scatter(XY_train[:, 0], XY_train[:, 1], z_train, c='blue', s=30)
ax.scatter(XY_train[:, 0], XY_train[:, 1], variable_adicional, c='green', s=40)

# Configurar etiquetas y título
ax.set_xlabel('Eje X')
ax.set_ylabel('Eje Y')
ax.set_zlabel('Eje Z')
ax.set_title('Regresion Lineal Multiple')

# Mostrar el gráfico
plt.show()